<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Request与BeautifulSoup下的网络爬虫 | SuoNi&#39;blog</title>
<link rel="shortcut icon" href="https://NCUczy.github.io/favicon.ico?v=1616851881340">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://NCUczy.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Request与BeautifulSoup下的网络爬虫 | SuoNi&#39;blog - Atom Feed" href="https://NCUczy.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="import os
import shutil

import requests
from lxml import etree


class MZiTu:

    # 初始化对象属性
    def __init__(self):
  ..." />
    <meta name="keywords" content="爬虫,Python" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://NCUczy.github.io">
  <img class="avatar" src="https://NCUczy.github.io/images/avatar.png?v=1616851881340" alt="">
  </a>
  <h1 class="site-title">
    SuoNi&#39;blog
  </h1>
  <p class="site-description">
    最是人间留不住，镜辞朱颜花辞树。
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="https://space.bilibili.com/355646962" class="menu" target="_blank">
          B站
        </a>
      
    
      
        <a href="https://www.luogu.com.cn/user/398483" class="menu" target="_blank">
          洛谷
        </a>
      
    
      
        <a href="https://y.qq.com/n/m/detail/taoge/index.html?id=2409427962" class="menu" target="_blank">
          歌单
        </a>
      
    
      
        <a href="https://NCUczy.github.io/post/jian-jie" class="menu">
          作者
        </a>
      
    
  </div>
  <div class="social-container">
    
      
        <a href="https://github.com/NCUczy/NCUczy.github.io" target="_blank">
          <i class="ri-github-line"></i>
        </a>
      
    
      
        <a href="https://twitter.com/suoni1919" target="_blank">
          <i class="ri-twitter-line"></i>
        </a>
      
    
      
        <a href="https://weibo.com/6602209984/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo" target="_blank">
          <i class="ri-weibo-line"></i>
        </a>
      
    
      
        <a href="https://www.zhihu.com/people/jun-xiao-57-8" target="_blank">
          <i class="ri-zhihu-line"></i>
        </a>
      
    
      
        <a href="https://www.facebook.com/suo.ni.372/" target="_blank">
          <i class="ri-facebook-line"></i>
        </a>
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Request与BeautifulSoup下的网络爬虫
            </h2>
            <div class="post-info">
              <span>
                2021-01-10
              </span>
              <span>
                4 min read
              </span>
              
                <a href="https://NCUczy.github.io/tag/Y7Xebm38u/" class="post-tag">
                  # 爬虫
                </a>
              
                <a href="https://NCUczy.github.io/tag/Y07TcSyG7/" class="post-tag">
                  # Python
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <pre><code class="language-python">import os
import shutil

import requests
from lxml import etree


class MZiTu:

    # 初始化对象属性
    def __init__(self):
        self.index_url = &quot;https://www.mzitu.com/&quot;
        self.headers = {
            &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&quot;,
            &quot;Referer&quot;: &quot;https://www.mzitu.com/&quot;
        }
        self.path = input('请输入保存的文件夹名(默认为--meizitu--):')

    # 发送request请求
    def send_request(self, url):
        return requests.get(url, headers=self.headers, timeout=3).content

    # 解析每页的数据
    def parse(self, html_str):
        html = etree.HTML(html_str)
        titles = html.xpath('//img[@class=&quot;lazy&quot;]')
        content_list = []
        for title in titles:
            item = {}
            item['title'] = title.xpath('./@alt')[0]
            item['href'] = title.xpath('../@href')[0]
            content_list.append(item)
            # print(item)
        # print(content_list)
        next_url = html.xpath('//a[contains(text(),&quot;下一页&quot;)]/@href')
        next_url = next_url[0] if next_url else None
        return content_list, next_url

    # 获取每张写真集的img_url
    def get_img_url(self, detail_html):
        html = etree.HTML(detail_html)
        img_url = html.xpath('//div[@class=&quot;main-image&quot;]/p/a/img/@src')[0]
        next_img_url = html.xpath('//span[contains(text(),&quot;下一页&quot;)]/../@href')
        next_url = next_img_url[0] if next_img_url else None
        return img_url, next_url

    # 判断文件夹是否存在,不存在创建文件夹
    def mkdir(self, dir_name, img_url_list):
        total_image = len(img_url_list)
        meizi_dir = self.path if self.path else 'meizitu'
        final_dir = meizi_dir + '/' + '[{}P]'.format(str(total_image)) + dir_name
        if os.path.exists(final_dir):
            shutil.rmtree(final_dir)
        os.makedirs(final_dir)
        return final_dir

    # 保存img
    def save_image(self, j, final_dir, img_url_list):
        for img_url in img_url_list:
            try:
                image_data = self.send_request(img_url)
            except:
                continue
            file_name = final_dir + '/' + img_url[-9:]
            with open(file_name, 'wb') as image:
                image.write(image_data)
            print(&quot;*&quot; * 14, img_url, '下载完成', &quot;*&quot; * 14)
        print(&quot;-&quot; * 29 + '第{}张写真集保存完毕'.format(int(j)) + &quot;-&quot; * 30 + '\n\n')

    # 运行爬虫
    def run(self):
        # 1. 获取url
        next_page_url = self.index_url
        i = 1
        # 获取每页的url地址并解析
        while True:
            # 2. 发送请求,获取响应
            try:
                html_str = self.send_request(next_page_url).decode()
            except:
                continue
            # 3. 解析数据
            content_list, next_page_url = self.parse(html_str)
            # 4. 获取详情页的img
            j = 1
            # 获取每张写真集并解析
            for content in content_list:
                img_url_list = []
                print(&quot;-&quot; * 30 + '正在获取第{}张写真集'.format(int(j)) + &quot;-&quot; * 30)
                # 获取每张写真集的img_url
                # 第一页的img地址
                dir_name = content['title']
                next_url = content['href']
                # print(next_url)
                # 获取每张写真集每页的img_url
                while True:
                    try:
                        detail_html = self.send_request(next_url).decode()
                    except:
                        continue
                    img_url, next_url = self.get_img_url(detail_html)
                    # 第二页的img地址
                    # detail_html = self.send_request(next_url)
                    # img_url, next_url =self.get_img_url(detail_html)
                    img_url_list.append(img_url)
                    if next_url is None:
                        break
                # 保存图片
                if img_url_list:
                    final_dir = self.mkdir(dir_name, img_url_list)
                    self.save_image(j, final_dir, img_url_list)
                j += 1
            print(&quot;-&quot; * 32 + '第{}页获取完成'.format(int(i)) + &quot;-&quot; * 32 + '\n\n')
            i += 1
            if next_page_url is None:
                break


def main():
    mz = MZiTu()
    mz.run()


if __name__ == '__main__':
    main()
</code></pre>
<p>自动获取网络美女写真的爬虫</p>
<p>（阿弥陀佛</p>

              </div>
              <div class="toc-container">
                
              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://NCUczy.github.io/post/贪吃蛇/">
              <h3 class="post-title">
                pygame下的贪吃蛇开发
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: 'e6dade07380d61e44eb4',
    clientSecret: 'b3e442437853316ed380c49d0a49a7b36e00e809',
    repo: 'NCUczy.github.io',
    owner: 'NCUczy',
    admin: ['NCUczy'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  且听风吟
  <a class="rss" href="https://NCUczy.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
